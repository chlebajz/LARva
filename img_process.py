import cv2
import numpy as np
import math

class Cone:
    '''Class to store found cones'''
    def __init__(self, color, coord, standing):
        self.color = color
        self.coord = coord
        self.standing = standing
    def __repr__(self):      # for printing
        stand = "standing" if self.standing else "fallen"
        # Python 3
        # return "position: [{:.3}, {:.3}, {:.3}]".format(self.x, self.y, self.z) + ", color: '" + self.color + "', state: " + stand
        # Python 2
        return "\n{position: " + str(self.coord) + ", color: '" + self.color + "', state: " + stand + "}"

class Coordinates:
    '''Class to store coordinates'''
    def __init__(self, x, y, z):
        self.x = x
        self.y = y
        self.z = z
    def __repr__(self):  # for printing
        # Python 3
        # return "[{:.3}, {:.3}, {:.3}]".format(self.x, self.y, self.z)
        # Python 2
        return "[%.3f, %.3f, %.3f]" % (self.x, self.y, self.z)
    def numpyfy(self):
        return np.array([self.x, self.y, self.z])

def distance(robot_pos, Cone): # function to get the distance from the cone
    return math.sqrt(pow((Cone.x - robot_pos[0]), 2) + pow((Cone.y - robot_pos[1]), 2) + pow((Cone.z - robot_pos[2]), 2))

def print_cones(cones, robot_pos): # for debugging purposes
    for i in range(len(cones)):
        print("Cone {}:".format(i), cones[i], "distance:", distance(robot_pos, cones[i]))

def process(img, depth_img, K_RGB):
    def distance_from_rgb(x, y, w, h, standing):
        # code from LAR laboratory
        if standing:
            u1_homogeneous = np.array([x, (y + h) / 2, 1])
            u2_homogeneous = np.array([x + w, (y + h) / 2, 1])
        else:
            u1_homogeneous = np.array([(x + w) / 2, y, 1])
            u2_homogeneous = np.array([(x + w) / 2, (y + h), 1])
        x1 = np.matmul(np.linalg.inv(K_RGB), u1_homogeneous)
        x2 = np.matmul(np.linalg.inv(K_RGB), u2_homogeneous)
        cos_alpha = np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))
        alpha = np.arccos(cos_alpha)
        return 0.025 / np.sin(alpha / 2)

    def camera_coord(x, y, z):
        u_mid_homogeneous = np.array([x, y, 1])
        return np.matmul(np.linalg.inv(K_RGB), u_mid_homogeneous * z)

    def convert_to_robot_coord(coordinates):
        T = np.array([[0.0, 0.0, 1.0, -0.087], #generated by quaternion_to_rot_matrix.py
                       [-1.0, 0.0, 0.0, 0.013],
                       [0.0, -1.0, 0.0, 0.287],
                       [0, 0, 0, 1]])
        coord = np.append(coordinates, [1])
        new_coord = np.matmul(T, coord)
        return Coordinates(new_coord[0], new_coord[1], new_coord[2])

    HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    color_min = [(0, 35, 25), (49, 30, 25), (107, 30, 25)] # for R, G, B in format (h_min, s_min, v_min)
    color_max = [(15, 255, 255), (77, 255, 255), (135, 255, 255)] # for R, G, B in format (h_max, s_max, v_max)
    cones = []

    for i in range(3):
        color = "Red"
        if i == 1: color = "Green"
        elif i == 2: color = "Blue"
        frame_threshold = cv2.inRange(HSV, color_min[i], color_max[i])
        contours, hierarchy = cv2.findContours(frame_threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < 500:
                continue
            x, y, w, h = cv2.boundingRect(cnt)
            approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)
            if len(approx) > 4: # not a square
                continue
            if float(h) / w > 8: #standing Cone
                standing = True
            elif float(w) / h > 8: # Cone on the floor
                standing = False
            else: #invalid ratio
                continue
            mid = (int(x + w / 2), int(y + h / 2))
            z = depth_img[mid[1], mid[0]]
            if z is None:
                z = distance_from_rgb(x, y, w, h, standing)
            else:
                z += 0.025 # convert to distance from the middle of the bannsiter
            pos = camera_coord(mid[0], mid[1], z) # position in camera coordinates
            pos = convert_to_robot_coord(pos)
            new = Cone(color, pos, standing)
            cones.append(new)
    return cones

if __name__ == "__main__": # For testing purposes
    img = cv2.imread("Data/foto1.png")
    depth = np.full((480, 640), None)
    K_RGB = np.array([[554.25469119, 0, 320.5],
                      [0, 554.25469119, 240.5],
                      [0, 0, 1]])

    cones = process(img, depth, K_RGB)
    print(cones)
    cv2.imshow("Image", img)
    cv2.waitKey(0)